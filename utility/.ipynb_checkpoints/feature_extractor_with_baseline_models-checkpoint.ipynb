{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import statistics\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "    \n",
    "TRAIN = '../data/train/training_data.csv'\n",
    "train_data = pd.read_csv(TRAIN, index_col=1)\n",
    "dev_data = pd.read_csv('../data/dev/development_data.csv', index_col=1)\n",
    "\n",
    "tweets = train_data[['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words_set = set(open(\"bad-words.txt\").read().split())\n",
    "words_set = set(open(\"allwords.txt\").read().split())\n",
    "words_set = set(item.lower() for item in words_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigrams for the data splitting on spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigrams():\n",
    "    unigrams = Counter()\n",
    "    for row_index, row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        for word in s:\n",
    "            unigrams[word] += 1\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make count features binary by finding median values over entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into quartiles?\n",
    "def find_quartile_values(counts):\n",
    "    counts.sort()\n",
    "    first = np.quantile(counts, .25)\n",
    "    second = np.quantile(counts, .5)\n",
    "    third = np.quantile(counts, .75)\n",
    "    return [first, second, third] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_at_bins():\n",
    "    at_counts = []\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        count = sum(map(lambda word : 1 if '@' in word else 0, s))\n",
    "        at_counts.append(count)\n",
    "    return find_quartile_values(at_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_num_token_bins():\n",
    "    lens = []\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        count = len(s)\n",
    "        lens.append(count)\n",
    "    \n",
    "    return find_quartile_values(lens)\n",
    "#     lens.sort()\n",
    "#     median = statistics.median(lens) #Get Median for binning\n",
    "    \n",
    "#     return [0, median]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_swear_bins():\n",
    "    bad_words_counts = []\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        tot_bad = 0\n",
    "        for word in s:\n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\";\",\"\")\n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        bad_words_counts.append(tot_bad)\n",
    "    \n",
    "    return find_quartile_values(bad_words_counts)\n",
    "#     bad_words_counts.sort()\n",
    "#     median = statistics.median(bad_words_counts) #Get Median for binning\n",
    "    \n",
    "#     return [0, median]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mention_bins():\n",
    "    mentions = []\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        count = sum(map(lambda word : 1 if '@' in word else 0, s))\n",
    "        lens.append(count)\n",
    "    \n",
    "    return find_quartile_values(mentions)\n",
    "#     mentions.sort()\n",
    "#     median = statistics.median(mentions) #Get Median for binning\n",
    "    \n",
    "#     return [0, median]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hashtag_bins():\n",
    "    hashtag_counts = []\n",
    "    at_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        count = sum(map(lambda word : 1 if '#' in word else 0, s))\n",
    "        hashtag_counts.append(count)\n",
    "    \n",
    "    return find_quartile_values(hashtag_counts)\n",
    "#     hashtag_counts.sort()\n",
    "#     median = statistics.median(hashtag_counts) #Get Median for binning\n",
    "    \n",
    "#     return [0, median]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_misspelling_bins():\n",
    "    misspell_counts = []\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        tot_misspelled = 0\n",
    "        for word in s:\n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\";\",\"\")\n",
    "            if word.lower() not in words_set:\n",
    "                tot_misspelled+=1\n",
    "        misspell_counts.append(tot_misspelled)\n",
    "    \n",
    "    return find_quartile_values(misspell_counts)\n",
    "#     misspell_counts.sort()\n",
    "#     median = statistics.median(misspell_counts)\n",
    "#     return [0, median]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bins contain the splits for which bin a tweet's feature counts will land in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_token_bins = make_num_token_bins()\n",
    "swear_bins = make_swear_bins()\n",
    "at_bins = make_at_bins()\n",
    "hashtag_bins = make_hashtag_bins()\n",
    "misspell_bins =  make_misspelling_bins()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_more_upper(tweet):\n",
    "    total_caps = sum(map(lambda ch : 1 if ch.isupper() else 0, tweet))\n",
    "    if total_caps > len(tweet) // 2:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_consecutive_punc(tweet):\n",
    "    for word in tweet.split():\n",
    "        if 'http://' in word: continue\n",
    "        for i in range(len(word)-1):\n",
    "            if word[i] in string.punctuation and word[i+1] in string.punctuation:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_person = ['he', 'she', 'they', 'him', 'her', 'them', 'his', 'hers', 'their', 'theirs', 'themselves', 'himself', 'herself']\n",
    "second_person = ['you', 'your', 'yours']\n",
    "first_person =['i', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if first word in tweet is a third person pronoun. Also check if number of third person pronouns is greater\n",
    "# than first person pronouns\n",
    "def get_pronouns(tweet):\n",
    "    first_pronoun = 0\n",
    "    third_and_second_greater_than_first = 0\n",
    "    words = tweet.split()\n",
    "    if words[0] in third_person or words[0] in second_person: \n",
    "        first_pronoun = 1\n",
    "    \n",
    "    first_person_count = 0\n",
    "    third_second_person_count = 0\n",
    "    for word in words:\n",
    "        if word in third_person or word in second_person:\n",
    "            third_second_person_count += 1\n",
    "        elif word in first_person:\n",
    "            first_person_count += 1\n",
    "            \n",
    "    if first_person_count < third_second_person_count:\n",
    "        third_and_second_greater_than_first = 1\n",
    "       \n",
    "    return first_pronoun, third_and_second_greater_than_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cite lexicon:\n",
    "    Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \n",
    "        Proceedings of the ACM SIGKDD International Conference on Knowledge \n",
    "        Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \n",
    "        Washington, USA,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = set(open(\"opinion-lexicon-English/positive-words.txt\").read().split())\n",
    "neg_words = set(open(\"opinion-lexicon-English/negative-words.txt\").read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns 1, 1 if negative words outnumber positive words and there are no positive words\n",
    "def get_sentiment(tweet):\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    for word in tweet.split():\n",
    "        if word in pos_words:\n",
    "            pos_count += 1\n",
    "        if word in neg_words:\n",
    "            neg_count += 1\n",
    "    if neg_count > pos_count:\n",
    "        if pos_count > 0:\n",
    "            return 1, 0\n",
    "        else:\n",
    "            return 1, 1\n",
    "    else:\n",
    "        if pos_count > 0:\n",
    "            return 0, 0\n",
    "        else:\n",
    "            return 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns one if a word in the tweet has non alphanumeric characters (not including punctuation at the end of a word)\n",
    "def contains_non_alphanum(tweet):\n",
    "    words = tweet.split()\n",
    "    for word in words:\n",
    "        if not word.isalnum():\n",
    "            if word[-1] not in string.punctuation:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-a96090d81629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find most common unigrams\n",
    "unigram_counts = get_unigrams()\n",
    "top_unigrams = unigram_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each count feature has four bins: 1 for < 25th percentile, 2 for < 50th percentile, \n",
    "#3 for < 75th percentile, and 4 for < 100th percentile\n",
    "def find_bin(count, bin_name):\n",
    "    for i in range(len(bin_name)):\n",
    "        if count < bin_name[i]:\n",
    "            return i + 1\n",
    "    return len(bin_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the tweets by getting their feature representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(tweets, judgements):\n",
    "#     for word in [u[0] for u in top_unigrams]:\n",
    "#         tweets[word] = tweets['tweet'].str.contains(word).astype(int)\n",
    "    word_counts = []\n",
    "    swear_counts = []\n",
    "    at_counts = []\n",
    "    contains_at = []\n",
    "    hashtag_counts = []\n",
    "    contains_hashtag = []\n",
    "    consecutive_punc = []\n",
    "    more_upper = []\n",
    "    first_pronoun = []\n",
    "    fewer_first_person = []\n",
    "    more_negative = []\n",
    "    no_positive = []\n",
    "    contains_url = []\n",
    "    not_alphanum = []\n",
    "    misspellings = []\n",
    "    disagreements = []\n",
    "    \n",
    "    for tweet in tweets['tweet']:\n",
    "        #count tokens\n",
    "        tweet_words = tweet.split()\n",
    "        num_token_bin = find_bin(len(tweet_words), num_token_bins)\n",
    "        word_counts.append(num_token_bin)\n",
    "        \n",
    "        #count swear words\n",
    "        tot_bad = 0\n",
    "        for word in tweet_words:                #Use regexs? \n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        swear_bin = find_bin(tot_bad, swear_bins)\n",
    "        swear_counts.append(swear_bin)\n",
    "        \n",
    "        #count mentions\n",
    "        at_count = tweet.count('@')\n",
    "        if at_count > 0:\n",
    "            contains_at.append(1)\n",
    "        else:\n",
    "            contains_at.append(0)\n",
    "        at_bin = find_bin(at_count, at_bins)\n",
    "        at_counts.append(at_bin)\n",
    "        \n",
    "        #count hashtags\n",
    "        hash_count = tweet.count('#')\n",
    "        if hash_count > 0:\n",
    "            contains_hashtag.append(1)\n",
    "        else:\n",
    "            contains_hashtag.append(0)\n",
    "        hash_bin = find_bin(hash_count, hashtag_bins)\n",
    "        hashtag_counts.append(hash_bin)\n",
    "        \n",
    "        #count misspellings\n",
    "        misspell_count = 0\n",
    "        for word in tweet_words:\n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\";\",\"\")\n",
    "            if word.lower() not in words_set:\n",
    "                misspell_count+=1\n",
    "        misspell_bin = find_bin(misspell_count, misspell_bins)\n",
    "        misspellings.append(misspell_bin)\n",
    "        \n",
    "        more_upper.append(has_more_upper(tweet))\n",
    "        consecutive_punc.append(has_consecutive_punc(tweet))\n",
    "        first, more = get_pronouns(tweet)\n",
    "        first_pronoun.append(first)\n",
    "        fewer_first_person.append(more)\n",
    "        \n",
    "        more_neg, pos = get_sentiment(tweet)\n",
    "        more_negative.append(more_neg)\n",
    "        no_positive.append(pos)\n",
    "        \n",
    "        if 'http://' in tweet:\n",
    "            contains_url.append(1)\n",
    "        else:\n",
    "            contains_url.append(0)\n",
    "            \n",
    "        not_alphanum.append(contains_non_alphanum(tweet))\n",
    "        \n",
    "        #See if there were disagreements about classification\n",
    "        i = tweets.loc[tweets['tweet']==tweet].index[0]\n",
    "        total_votes = judgements.at[i, 'count']\n",
    "        if (judgements.at[i, 'hate_speech'] == total_votes) or (judgements.at[i, 'offensive_language'] == total_votes)\\\n",
    "            or (judgements.at[i, 'neither'] == total_votes):\n",
    "            disagreements.append(0)\n",
    "        else:\n",
    "            disagreements.append(1)\n",
    "        \n",
    "\n",
    "    tweets['Word Counts'] = word_counts\n",
    "    tweets['Swear Counts'] = swear_counts\n",
    "    tweets['@ Counts'] = at_counts\n",
    "    tweets['Mention'] = contains_at\n",
    "    tweets['Hashtag Counts'] = hashtag_counts\n",
    "    tweets['Contains Hashtag'] = contains_hashtag\n",
    "    tweets['Consecutive Punctuation'] = consecutive_punc\n",
    "    tweets['Majority Uppercase Letters'] = more_upper\n",
    "    tweets['First Word Second or Third Person Pronoun'] = first_pronoun\n",
    "    tweets['More Second or Third Person Pronouns than First'] = fewer_first_person\n",
    "    tweets['Majority Negative Words'] = more_negative\n",
    "    tweets['No Positive Words'] = no_positive\n",
    "    tweets['Contains URL'] = contains_url\n",
    "    tweets['Contains Non Alphanumeric Word'] = not_alphanum\n",
    "    tweets['Misspelling Count'] = misspellings\n",
    "    tweets['Judgement Disagreements'] = disagreements\n",
    "    X = tweets[[col for col in tweets.columns if col!=\"tweet\"]].values\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine train and dev sets for k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data, dev_data], sort=False)\n",
    "tweets = data[['tweet']]\n",
    "judgements = data[['count', 'hate_speech', 'offensive_language', 'neither']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "X = process_tweets(tweets, judgements)\n",
    "y = data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22214, 16)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 10-fold cross validation on combined training and dev sets on LR, SVM, and NB models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(fit_intercept=True, max_iter=1000, solver='lbfgs', multi_class='ovr')\n",
    "lr_y_pred = cross_val_predict(LR, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1282\n",
      "           1       0.86      0.92      0.89     17186\n",
      "           2       0.60      0.59      0.60      3746\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     22214\n",
      "   macro avg       0.49      0.51      0.50     22214\n",
      "weighted avg       0.77      0.82      0.79     22214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"LR:\", classification_report(y, lr_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1282\n",
      "           1       0.87      0.92      0.89     17186\n",
      "           2       0.61      0.64      0.62      3746\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     22214\n",
      "   macro avg       0.49      0.52      0.51     22214\n",
      "weighted avg       0.77      0.82      0.80     22214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto') \n",
    "svm_y_pred = cross_val_predict(svm, X, y, cv=cv)\n",
    "print(classification_report(y, svm_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.99      0.11      1282\n",
      "           1       0.88      0.00      0.00     17186\n",
      "           2       0.72      0.13      0.22      3746\n",
      "\n",
      "   micro avg       0.08      0.08      0.08     22214\n",
      "   macro avg       0.55      0.37      0.11     22214\n",
      "weighted avg       0.80      0.08      0.05     22214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "nb_y_pred = cross_val_predict(gnb, X, y, cv=cv)\n",
    "print(classification_report(y, nb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
