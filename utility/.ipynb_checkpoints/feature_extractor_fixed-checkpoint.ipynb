{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from twitter_preprocess import *\n",
    "import csv\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import emoji\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import statistics\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "    \n",
    "TRAIN = '../data/train/training_data.csv'\n",
    "train_data = pd.read_csv(TRAIN, index_col=1)\n",
    "dev_data = pd.read_csv('../data/dev/development_data.csv', index_col=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bin(curr_dictionary, median):\n",
    "    swear_bins = [{},{},{}] #bins for < mean, == mean, > mean\n",
    "    for tweet, count in curr_dictionary.items():\n",
    "        if count == median:\n",
    "            swear_bins[1][tweet] = count\n",
    "        elif count < median:\n",
    "            swear_bins[0][tweet] = count\n",
    "        else:\n",
    "            swear_bins[2][tweet] = count\n",
    "    return swear_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unigram counts for data\n",
    "def get_unigrams_splitBySpace():\n",
    "    unigrams = Counter()\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index, row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        for word in s:\n",
    "            unigrams[word] += 1\n",
    "    return unigrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = get_unigrams_splitBySpace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unigram counts for data\n",
    "def get_unigrams_nltkTokenizer():\n",
    "    uni = Counter()\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index, row in tweets.iterrows():\n",
    "        s = tknzr.tokenize(row['tweet'])\n",
    "        for word in s:\n",
    "            uni[word] += 1  \n",
    "    return uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate n-gram, note here n = 5\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def get_ngrams(n):\n",
    "    n_grams = Counter()\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index, row in tweets.iterrows():\n",
    "        s = tknzr.tokenize(row['tweet'])\n",
    "        tokens = [token for token in s if token != \"\"]\n",
    "        output = list(ngrams(tokens, n))\n",
    "        n_grams = Counter(output)\n",
    "    return n_grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cannot bin\n",
    "def get_bigrams():\n",
    "    bigrams = Counter()\n",
    "    tweets = train_data[['tweet']]\n",
    "    start = \"<s>\"\n",
    "    end = \"</s>\"\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        word = start + \" \" + s[0]\n",
    "        bigrams[word] += 1\n",
    "        for i in range(len(s)-1):\n",
    "            word = s[i] + \" \" + s[i+1]\n",
    "            bigrams[word] += 1\n",
    "        word = s[len(s) - 1] + \" \" + end\n",
    "        bigrams[word] += 1\n",
    "    #print(bigrams)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cannot Bin.\n",
    "#Gets the average word counts for data\n",
    "#maybe split tweet on more than just whitespace ie ;:,.')(\n",
    "# def get_avg_wc():\n",
    "#     wcs = {}\n",
    "#     tweets = train_data[['tweet']]\n",
    "#     for row_index,row in tweets.iterrows():\n",
    "#         s = row['tweet'].split()\n",
    "#         tot = 0.\n",
    "#         for word in s:\n",
    "#             if \"http://\" in word: continue #ignore hyperlinks\n",
    "#             tot += len(word)\n",
    "#         wcs[' '.join(s)] = tot / len(s)\n",
    "#     return wcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the count of '@'s in the data\n",
    "def make_at_bins():\n",
    "    ats = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    at_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        count = sum(map(lambda word : 1 if '@' in word else 0, s))\n",
    "        at_sum += count\n",
    "        ats[' '.join(s)] = count\n",
    "        \n",
    "    val_list = list(ats.values())\n",
    "    val_list.sort()\n",
    "    median = statistics.median(val_list) #Get Median for binning\n",
    "    \n",
    "    return make_bin(ats, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_len_bins():\n",
    "    lens = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    len_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        count = len(row['tweet'].split())\n",
    "        len_sum += count\n",
    "        lens[' '.join(row['tweet'])] = count\n",
    "        \n",
    "    val_list = list(lens.values())\n",
    "    val_list.sort()\n",
    "    median = statistics.median(val_list) #Get Median for binning\n",
    "    \n",
    "    return make_bin(lens, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the count of swear words in tweets\n",
    "#potentially use regex's to catch purposeful mispellings & other nuances\n",
    "def make_swear_bins():\n",
    "    tweets = train_data[['tweet']]\n",
    "    bad_words_set = set(open(\"bad-words.txt\").read().split())\n",
    "    bad_words_count = {}\n",
    "    swear_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        tot_bad = 0\n",
    "        for word in s:\n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\";\",\"\")\n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        swear_sum+= tot_bad\n",
    "        bad_words_count[\" \".join(s)] = tot_bad\n",
    "        \n",
    "    val_list = list(bad_words_count.values())\n",
    "    val_list.sort()\n",
    "    median = statistics.median(val_list) #Get Median for binning\n",
    "    \n",
    "    return make_bin(bad_words_count, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_mention():\n",
    "    mentions = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        res = False\n",
    "        for word in s:\n",
    "            if '@' in word:\n",
    "                mentions[' '.join(s)] = 1\n",
    "                res = True\n",
    "        if not res:\n",
    "            mentions[' '.join(s)] = 0\n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_misspelling_bins():\n",
    "    tweets = train_data[['tweet']]\n",
    "    words_set = set(open(\"all_words.txt\").read().split())\n",
    "    words_set = set(item.lower() for item in words_set)  #Convert words to all lowercase\n",
    "    misspell_count = {}\n",
    "    misspell_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        tot_misspelled = 0\n",
    "        for word in s:\n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\";\",\"\")\n",
    "            if word.lower() not in words_set:\n",
    "                tot_misspelled+=1\n",
    "        misspell_sum += tot_misspelled\n",
    "        misspell_count[\" \".join(s)] = tot_misspelled\n",
    "    \n",
    "    val_list = list(misspell_count.values())\n",
    "    val_list.sort()\n",
    "    median = statistics.median(val_list) #Get Median for binning\n",
    "    \n",
    "    return make_bin(misspell_count, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hashtag_bins():\n",
    "    hashtags_count = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    at_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        count = sum(map(lambda word : 1 if '#' in word else 0, s))\n",
    "        at_sum += count\n",
    "        hashtags_count[' '.join(s)] = count\n",
    "    val_list = list(hashtags_count.values())\n",
    "    val_list.sort()\n",
    "    median = statistics.median(val_list) #Get Median for binning\n",
    "    \n",
    "    return make_bin(hashtags_count, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_hashtag(tweets):\n",
    "    hashtags = {}\n",
    "    #tweets = train_data[['tweet']]\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        s_str = ' '.join(s)\n",
    "        if '#' in s_str:\n",
    "            hashtags[s_str] = 1\n",
    "            continue\n",
    "        hashtags[s_str] = 0\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most samples evaluate to 0 \n",
    "def contains_more_uppercase():\n",
    "    maj_uppercase = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        s_str = ' '.join(s)\n",
    "        total_caps = sum(map(lambda ch : 1 if ch.isupper() else 0, s_str))\n",
    "        if total_caps > len(s_str) // 2:\n",
    "            maj_uppercase[s_str] = 1\n",
    "            continue\n",
    "        maj_uppercase[s_str] = 0\n",
    "    return maj_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM_uni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR_bi, SVM_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR_tri, SVM_tritop_unigrams = unigram_counts.most_common(100)\n",
    "# top_tokenized = uni_tokenizer_counts.most_common(100)\n",
    "# data = pd.concat([train_data, dev_data])\n",
    "# top_bigrams = bigram_counts.most_common(100)\n",
    "# data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bin(count, bin_name):\n",
    "    for i in range(len(bin_name)):\n",
    "        if count < bin_name[i]:\n",
    "            return i\n",
    "    return len(bin_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(tweets):\n",
    "    for word in [u[0] for u in top_unigrams]:\n",
    "        tweets[word] = tweets['tweet'].str.contains(word).astype(int)\n",
    "\n",
    "    #for all counts, just store which bin the count falls into\n",
    "    word_counts = []\n",
    "    swear_counts = []\n",
    "    at_counts = []\n",
    "    contains_at = []\n",
    "    hashtag_counts = []\n",
    "    contains_hashtag = []\n",
    "    bad_words_set = set(open(\"bad-words.txt\").read().split())\n",
    "\n",
    "    for tweet in tweets['tweet']:\n",
    "        tweet_words = tweet.split()\n",
    "        word_len_bin = find_bin(len(tweet_words), word_len_bins)\n",
    "        word_counts.append(word_len_bin)\n",
    "        tot_bad = 0\n",
    "\n",
    "        for word in tweet_words:                #Use regexs? \n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        swear_bin = find_bin(tot_bad, swear_bins)\n",
    "        swear_counts.append(swear_bin)\n",
    "        at_count = tweet_words.count('@')\n",
    "        \n",
    "        if at_count > 0:\n",
    "            contains_at.append(1)\n",
    "        else:\n",
    "            contains_at.append(0)\n",
    "        at_bin = find_bin(at_count, at_bins)\n",
    "        at_counts.append(at_bin)\n",
    "        \n",
    "        hash_count = tweet_words.count('#')\n",
    "        if hash_count > 0:\n",
    "            contains_hash.append(1)\n",
    "        else:\n",
    "            contains_hash.append(0)\n",
    "        hash_bin = find_bin(hash_count, hash_bins)\n",
    "        hash_counts.append(hash_bin)\n",
    "\n",
    "    tweets['Word Counts'] = word_counts\n",
    "    tweets['Swear Counts'] = swear_counts\n",
    "    tweets['@ Counts'] = at_counts\n",
    "    tweets['Mention'] = contains_at\n",
    "    tweets['Hashtag Counts'] = hashtag_counts\n",
    "    tweets['Contains Hashtag'] = contains_hashtag\n",
    "    X = tweets[[col for col in tweets.columns if col!=\"tweet\"]].values\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tokenized_tweets(tweets):\n",
    "    for word in [u[0] for u in top_tokenized]:\n",
    "        if len(word) > 1:\n",
    "            tweets[word] = tweets['tweet'].str.contains(word).astype(int)\n",
    "    word_counts = []\n",
    "    swear_counts = []\n",
    "    at_counts = []\n",
    "    bad_words_set = set(open(\"bad-words.txt\").read().split())\n",
    "\n",
    "    for tweet in tweets['tweet']:\n",
    "        tweet_words = tweet.split()\n",
    "        word_counts.append(len(tweet))\n",
    "        tot_bad = 0\n",
    "        for word in tweet:                #Use regexs? \n",
    "            #word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        swear_counts.append(tot_bad)\n",
    "        at_count = tweet.count('@')\n",
    "        at_counts.append(at_count)\n",
    "\n",
    "    tweets['Word Counts'] = word_counts\n",
    "    tweets['Swear Counts'] = swear_counts\n",
    "    tweets['@ Counts'] = at_counts\n",
    "    X_tokenized = tweets[[col for col in tweets.columns if col!=\"tweet\"]].values\n",
    "    return X_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = data[['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_len_bins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-a1148e959d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#X_tokenized = process_tokenized_tweets(tweets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-1990715d2d11>\u001b[0m in \u001b[0;36mprocess_tweets\u001b[0;34m(tweets)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtweet_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mword_len_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_len_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mword_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_len_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtot_bad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_len_bins' is not defined"
     ]
    }
   ],
   "source": [
    "X = process_tweets(tweets)\n",
    "#X_tokenized = process_tokenized_tweets(tweets)\n",
    "y = data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b4b058e10d01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlr_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LR:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_val_predict' is not defined"
     ]
    }
   ],
   "source": [
    "#evaluate the models and print out classification reports for 10-fold cross validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
    "LR = LogisticRegression(fit_intercept=True, max_iter=1000, solver='lbfgs', multi_class='ovr')\n",
    "\n",
    "lr_y_pred = cross_val_predict(LR, X, y, cv=cv)\n",
    "print(\"LR:\", classification_report(y, lr_y_pred))\n",
    "\n",
    "svm = SVC(gamma='auto') \n",
    "svm_y_pred = cross_val_predict(svm, X, y, cv=cv)\n",
    "print(\"SVM:\", classification_report(y, svm_y_pred))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "nb_y_pred = cross_val_predict(gnb, X, y, cv=cv)\n",
    "print(\"NB:\", classification_report(y, nb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the models and print out classification reports for 10-fold cross validation\n",
    "from sklearn.metrics import classification_report\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
    "LR = LogisticRegression(fit_intercept=True, max_iter=1000, solver='lbfgs', multi_class='ovr')\n",
    "\n",
    "lr_y_pred = cross_val_predict(LR, X, y, cv=cv)\n",
    "print(\"LR:\", classification_report(y, lr_y_pred))\n",
    "\n",
    "svm = SVC(gamma='auto') \n",
    "svm_y_pred = cross_val_predict(svm, X, y, cv=cv)\n",
    "print(\"SVM:\", classification_report(y, svm_y_pred))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "nb_y_pred = cross_val_predict(gnb, X, y, cv=cv)\n",
    "print(\"NB:\", classification_report(y, nb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 1, 1, 0],\n",
       "       [1, 0, 0, ..., 1, 1, 0],\n",
       "       [1, 1, 0, ..., 1, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 1, 1, 0],\n",
       "       [1, 0, 1, ..., 1, 1, 0],\n",
       "       [0, 0, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
    "LR_scores = []\n",
    "SVM_scores = []\n",
    "NB_scores = []\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    LR = LogisticRegression(fit_intercept=True, max_iter=1000, solver='lbfgs', multi_class='ovr')\n",
    "    svm = SVC(gamma='auto') \n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    \n",
    "    LR.fit(X_train, y_train)\n",
    "    y_LR_predict = LR.predict(X_test)\n",
    "    LR_scores.append(precision_recall_fscore_support(y_test, y_LR_predict, average='macro', labels=[0, 1, 2]))\n",
    "                     \n",
    "    svm.fit(X_train, y_train)\n",
    "    y_svm_predict = svm.predict(X_test)\n",
    "    SVM_scores.append(precision_recall_fscore_support(y_test, y_svm_predict, average='macro', labels=[0, 1, 2]))\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    y_NB_predict = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    NB_scores.append(precision_recall_fscore_support(y_test, y_NB_predict, average='macro', labels=[0, 1, 2]))\n",
    "#naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_precision(results):\n",
    "    total = 0\n",
    "    num_rows = 0\n",
    "    for row in results:\n",
    "        total += row[0]\n",
    "        num_rows += 1\n",
    "    return total / num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
    "LR_scores_tok = []\n",
    "SVM_scores_tok = []\n",
    "\n",
    "for train_index, test_index in cv.split(X_tokenized):\n",
    "    LR = LogisticRegression(fit_intercept=True, max_iter=1000, solver='lbfgs', multi_class='ovr')\n",
    "    svm = SVC(gamma='auto') \n",
    "    X_train, X_test, y_train, y_test = X_tokenized[train_index], X_tokenized[test_index], y[train_index], y[test_index]\n",
    "    LR.fit(X_train, y_train)\n",
    "    LR_scores_tok.append(LR.score(X_test, y_test))\n",
    "    svm.fit(X_train, y_train)\n",
    "    SVM_scores_tok.append(svm.score(X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8361836183618362,\n",
       " 0.8352835283528353,\n",
       " 0.851935193519352,\n",
       " 0.873987398739874,\n",
       " 0.8536695182350292,\n",
       " 0.8631247185952273,\n",
       " 0.8572714993246285,\n",
       " 0.8712291760468257,\n",
       " 0.8635749662314273,\n",
       " 0.8703286807744259]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_scores_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8618361836183618,\n",
       " 0.8550855085508551,\n",
       " 0.8672367236723673,\n",
       " 0.8861386138613861,\n",
       " 0.8716794236830256,\n",
       " 0.875281404772625,\n",
       " 0.8779828905898244,\n",
       " 0.8928410625844214,\n",
       " 0.8829356145880234,\n",
       " 0.8793336334984241]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8186318631863186,\n",
       " 0.8181818181818182,\n",
       " 0.833033303330333,\n",
       " 0.8424842484248425,\n",
       " 0.819900945520036,\n",
       " 0.8212516884286357,\n",
       " 0.829806393516434,\n",
       " 0.845114813147231,\n",
       " 0.820351193156236,\n",
       " 0.8460153084196308]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_scores_tok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8604860486048604,\n",
       " 0.8577857785778578,\n",
       " 0.864986498649865,\n",
       " 0.8771377137713772,\n",
       " 0.8680774425934263,\n",
       " 0.8671769473210266,\n",
       " 0.8766321476812247,\n",
       " 0.884736605132823,\n",
       " 0.8757316524088249,\n",
       " 0.8833858622242233]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_scoresLR_precision = get_avg_precision(LR_scores)\n",
    "SVM_precision = get_avg_precision(SVM_scores)\n",
    "NB_precision = get_avg_precision(NB_scores)\n",
    "LR_precision, SVM_precision, NB_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}