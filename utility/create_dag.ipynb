{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/cryptography/hazmat/primitives/constant_time.py:26: CryptographyDeprecationWarning: Support for your Python version is deprecated. The next version of cryptography will remove support. Please upgrade to a 2.7.x release that supports hmac.compare_digest as soon as possible.\n",
      "  utils.PersistentlyDeprecated2018,\n",
      "Collecting package metadata: done\n",
      "Solving environment: \\ "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} pomegranate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pomegranate\n",
    "#from pomegranate import BayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import networkx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import notears\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = '../data/train/training_data.csv'\n",
    "train_data = pd.read_csv(TRAIN, index_col=1)\n",
    "dev_data = pd.read_csv('../data/dev/development_data.csv', index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def get_ngrams(n):\n",
    "    n_grams = Counter()\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index, row in tweets.iterrows():\n",
    "        s = tknzr.tokenize(row['tweet'])\n",
    "        tokens = [token for token in s if token != \"\"]\n",
    "        output = list(ngrams(tokens, n))\n",
    "        n_grams = Counter(output)\n",
    "    return n_grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srizkall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "unis = get_ngrams(1)\n",
    "top_unigrams = unis.most_common(100)\n",
    "data = pd.concat([train_data, dev_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ngram_tweets(tweets, model):\n",
    "    for word in [u[0] for u in model]:\n",
    "        if len(word) > 1:\n",
    "            tweets[word] = tweets['tweet'].str.contains(word).astype(int)\n",
    "    word_counts = []\n",
    "    swear_counts = []\n",
    "    at_counts = []\n",
    "    bad_words_set = set(open(\"bad-words.txt\").read().split())\n",
    "\n",
    "    for tweet in tweets['tweet']:\n",
    "        tweet_words = tweet.split()\n",
    "        word_counts.append(len(tweet))\n",
    "        tot_bad = 0\n",
    "        for word in tweet:            \n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        swear_counts.append(tot_bad)\n",
    "        at_count = tweet.count('@')\n",
    "        at_counts.append(at_count)\n",
    "\n",
    "    tweets['Word Counts'] = word_counts\n",
    "    tweets['Swear Counts'] = swear_counts\n",
    "    tweets['@ Counts'] = at_counts\n",
    "    return tweets[[col for col in tweets.columns if col!=\"tweet\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srizkall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/srizkall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/srizkall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "tweets = data[['tweet']]\n",
    "X_uni = process_ngram_tweets(tweets, \"top_unigrams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets.values\n",
    "model = BayesianNetwork.from_samples(X, algorithm='exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
