{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from twitter_preprocess import *\n",
    "import csv\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import statistics\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "    \n",
    "TRAIN = '../data/train/training_data.csv'\n",
    "train_data = pd.read_csv(TRAIN, index_col=1)\n",
    "dev_data = pd.read_csv('../data/dev/development_data.csv', index_col=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bin(curr_dictionary, median):\n",
    "    swear_bins = [{},{},{}] #bins for < mean, == mean, > mean\n",
    "    for tweet, count in curr_dictionary.items():\n",
    "        if count == median:\n",
    "            swear_bins[1][tweet] = count\n",
    "        elif count < median:\n",
    "            swear_bins[0][tweet] = count\n",
    "        else:\n",
    "            swear_bins[2][tweet] = count\n",
    "    return swear_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unigram counts for data\n",
    "def get_unigrams_splitBySpace():\n",
    "    unigrams = Counter()\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index, row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        for word in s:\n",
    "            unigrams[word] += 1\n",
    "    return unigrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = get_unigrams_splitBySpace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unigram counts for data\n",
    "def get_unigrams_nltkTokenizer():\n",
    "    uni = Counter()\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index, row in tweets.iterrows():\n",
    "        s = tknzr.tokenize(row['tweet'])\n",
    "        for word in s:\n",
    "            uni[word] += 1  \n",
    "    return uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate n-gram, note here n = 5\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def get_ngrams(n):\n",
    "    n_grams = Counter()\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index, row in tweets.iterrows():\n",
    "        s = tknzr.tokenize(row['tweet'])\n",
    "        tokens = [token for token in s if token != \"\"]\n",
    "        output = list(ngrams(tokens, n))\n",
    "        n_grams = Counter(output)\n",
    "    return n_grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cannot bin\n",
    "def get_bigrams():\n",
    "    bigrams = Counter()\n",
    "    tweets = train_data[['tweet']]\n",
    "    start = \"<s>\"\n",
    "    end = \"</s>\"\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        word = start + \" \" + s[0]\n",
    "        bigrams[word] += 1\n",
    "        for i in range(len(s)-1):\n",
    "            word = s[i] + \" \" + s[i+1]\n",
    "            bigrams[word] += 1\n",
    "        word = s[len(s) - 1] + \" \" + end\n",
    "        bigrams[word] += 1\n",
    "    #print(bigrams)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cannot Bin.\n",
    "#Gets the average word counts for data\n",
    "#maybe split tweet on more than just whitespace ie ;:,.')(\n",
    "# def get_avg_wc():\n",
    "#     wcs = {}\n",
    "#     tweets = train_data[['tweet']]\n",
    "#     for row_index,row in tweets.iterrows():\n",
    "#         s = row['tweet'].split()\n",
    "#         tot = 0.\n",
    "#         for word in s:\n",
    "#             if \"http://\" in word: continue #ignore hyperlinks\n",
    "#             tot += len(word)\n",
    "#         wcs[' '.join(s)] = tot / len(s)\n",
    "#     return wcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the count of '@'s in the data\n",
    "def get_at_counts():\n",
    "    ats = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    at_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        count = sum(map(lambda word : 1 if '@' in word else 0, s))\n",
    "        at_sum += count\n",
    "        ats[' '.join(s)] = count\n",
    "        \n",
    "    val_list = list(ats.values())\n",
    "    val_list.sort()\n",
    "    median = statistics.median(val_list) #Get Median for binning\n",
    "    \n",
    "    return make_bin(ats, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the count of swear words in tweets\n",
    "#potentially use regex's to catch purposeful mispellings & other nuances\n",
    "def get_swear_counts():\n",
    "    tweets = train_data[['tweet']]\n",
    "    bad_words_set = set(open(\"bad-words.txt\").read().split())\n",
    "    bad_words_count = {}\n",
    "    swear_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        tot_bad = 0\n",
    "        for word in s:\n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\";\",\"\")\n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        swear_sum+= tot_bad\n",
    "        bad_words_count[\" \".join(s)] = tot_bad\n",
    "        \n",
    "    val_list = list(bad_words_count.values())\n",
    "    val_list.sort()\n",
    "    median = statistics.median(val_list) #Get Median for binning\n",
    "    \n",
    "    return make_bin(bad_words_count, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_mention():\n",
    "    mentions = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        res = False\n",
    "        for word in s:\n",
    "            if '@' in word:\n",
    "                mentions[' '.join(s)] = 1\n",
    "                res = True\n",
    "        if not res:\n",
    "            mentions[' '.join(s)] = 0\n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misspelling_counts():\n",
    "    tweets = train_data[['tweet']]\n",
    "    words_set = set(open(\"all_words.txt\").read().split())\n",
    "    words_set = set(item.lower() for item in words_set)  #Convert words to all lowercase\n",
    "    misspell_count = {}\n",
    "    misspell_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        tot_misspelled = 0\n",
    "        for word in s:\n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\";\",\"\")\n",
    "            if word.lower() not in words_set:\n",
    "                tot_misspelled+=1\n",
    "        misspell_sum += tot_misspelled\n",
    "        misspell_count[\" \".join(s)] = tot_misspelled\n",
    "    \n",
    "    val_list = list(misspell_count.values())\n",
    "    val_list.sort()\n",
    "    median = statistics.median(val_list) #Get Median for binning\n",
    "    \n",
    "    return make_bin(misspell_count, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtag_counts():\n",
    "    hashtags_count = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    at_sum = 0\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        count = sum(map(lambda word : 1 if '#' in word else 0, s))\n",
    "        at_sum += count\n",
    "        hashtags_count[' '.join(s)] = count\n",
    "    val_list = list(hashtags_count.values())\n",
    "    val_list.sort()\n",
    "    median = statistics.median(val_list) #Get Median for binning\n",
    "    \n",
    "    return make_bin(hashtags_count, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_hashtag():\n",
    "    hashtags = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        s_str = ' '.join(s)\n",
    "        if '#' in s_str:\n",
    "            hashtags[s_str] = 1\n",
    "            continue\n",
    "        hashtags[s_str] = 0\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most samples evaluate to 0 \n",
    "def contains_more_uppercase():\n",
    "    maj_uppercase = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        s_str = ' '.join(s)\n",
    "        total_caps = sum(map(lambda ch : 1 if ch.isupper() else 0, s_str))\n",
    "        if total_caps > len(s_str) // 2:\n",
    "            maj_uppercase[s_str] = 1\n",
    "            continue\n",
    "        maj_uppercase[s_str] = 0\n",
    "    return maj_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_consecutive_punc():\n",
    "    punc = {}\n",
    "    tweets = train_data[['tweet']]\n",
    "    for row_index,row in tweets.iterrows():\n",
    "        s = row['tweet'].split()\n",
    "        s_str = ' '.join(s)\n",
    "        res = False\n",
    "        for word in s:\n",
    "            if 'http://' in word: continue\n",
    "            for i in range(len(word)-1):\n",
    "                if word[i] in string.punctuation and word[i+1] in string.punctuation:\n",
    "                    punc[s_str] = 1\n",
    "                    res = True\n",
    "        if not res:\n",
    "            punc[s_str] = 0\n",
    "    return punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT WORKING YET\n",
    "# def contains_emoji():\n",
    "#     has_emoji = {}\n",
    "#     tweets = train_data[['tweet']]\n",
    "#     for row_index,row in tweets.iterrows():\n",
    "#         s = row['tweet'].split()\n",
    "#         s_str = ' '.join(s)\n",
    "#         res = False\n",
    "#         print (emoji.UNICODE_EMOJI)\n",
    "#         for emoji in emoji.UNICODE_EMOJI:\n",
    "#             if emoji in s_str:\n",
    "#                 has_emoji[s_str] = 1\n",
    "#                 res = True\n",
    "#                 break\n",
    "#         if not res:\n",
    "#             has_emoji[s_str] = 0\n",
    "#     return has_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'emoji' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-b1305834f0c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#contains_hashtag()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#has_consecutive_punc()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcontains_emoji\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-254-4ae4036cf8e6>\u001b[0m in \u001b[0;36mcontains_emoji\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0ms_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0memoji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNICODE_EMOJI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0memoji\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNICODE_EMOJI\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0memoji\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'emoji' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#unigram_counts = get_unigrams_splitBySpace()\n",
    "#unis = get_ngrams(1)\n",
    "#bigrams = get_ngrams(2)\n",
    "#trigrams = get_ngrams(3)\n",
    "#uni_tokenizer_counts = get_unigrams_nltkTokenizer()\n",
    "#bigram_counts = get_bigrams()\n",
    "#avg_wc = get_avg_wc()\n",
    "#get_at_counts()\n",
    "#get_swear_counts()\n",
    "#contains_mention()\n",
    "#get_misspelling_counts()\n",
    "#get_hashtag_counts()\n",
    "#contains_more_uppercase()\n",
    "#contains_hashtag()\n",
    "#has_consecutive_punc()\n",
    "#contains_emoji()    #NOT WORKING YET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-907486707f29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#get top 100 unigrams and bigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtop_unigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtop_bigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop_trigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#top_unigrams = unigram_counts.most_common(100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unis' is not defined"
     ]
    }
   ],
   "source": [
    "#get top 100 unigrams and bigrams\n",
    "top_unigrams = unis.most_common(100)\n",
    "top_bigrams = bigrams.most_common(100)\n",
    "top_trigrams = trigrams.most_common(100)\n",
    "#top_unigrams = unigram_counts.most_common(100)\n",
    "#top_tokenized = uni_tokenizer_counts.most_common(100)\n",
    "#top_bigrams = bigram_counts.most_common(100)\n",
    "data = pd.concat([train_data, dev_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ngram_tweets(tweets, model):\n",
    "    for word in [u[0] for u in model]:\n",
    "        if len(word) > 1:\n",
    "            tweets[word] = tweets['tweet'].str.contains(word).astype(int)\n",
    "    word_counts = []\n",
    "    swear_counts = []\n",
    "    at_counts = []\n",
    "    bad_words_set = set(open(\"bad-words.txt\").read().split())\n",
    "\n",
    "    for tweet in tweets['tweet']:\n",
    "        tweet_words = tweet.split()\n",
    "        word_counts.append(len(tweet))\n",
    "        tot_bad = 0\n",
    "        for word in tweet:            \n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        swear_counts.append(tot_bad)\n",
    "        at_count = tweet.count('@')\n",
    "        at_counts.append(at_count)\n",
    "\n",
    "    tweets['Word Counts'] = word_counts\n",
    "    tweets['Swear Counts'] = swear_counts\n",
    "    tweets['@ Counts'] = at_counts\n",
    "    return tweets[[col for col in tweets.columns if col!=\"tweet\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susanabenavidez/anaconda3/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/susanabenavidez/anaconda3/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/susanabenavidez/anaconda3/envs/nlu/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "tweets = data[['tweet']]\n",
    "X_uni = process_ngram_tweets(tweets, \"top_unigrams\")\n",
    "X_bi = process_ngram_tweets(tweets, \"top_bigrams\")\n",
    "X_tri = process_ngram_tweets(tweets, \"top_trigrams\")\n",
    "y = data['class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(model):\n",
    "    sample_size = len(model)\n",
    "    if sample_size > 10:\n",
    "        cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
    "    else: \n",
    "        cv = KFold(n_splits=3, random_state=42, shuffle=False)\n",
    "    LR_scores = []\n",
    "    SVM_scores = []\n",
    "\n",
    "    for train_index, test_index in cv.split(model):\n",
    "        LR = LogisticRegression(fit_intercept=True, max_iter=1000, solver='lbfgs', multi_class='ovr')\n",
    "        svm = SVC(gamma='auto') \n",
    "        X_train, X_test, y_train, y_test = model[train_index], model[test_index], y[train_index], y[test_index]\n",
    "        LR.fit(X_train, y_train)\n",
    "        LR_scores.append(LR.score(X_test, y_test))\n",
    "        svm.fit(X_train, y_train)\n",
    "        SVM_scores.append(svm.score(X_test, y_test))\n",
    "    return LR_scores, SVM_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_uni, SVM_uni = eval_model(X_uni)\n",
    "LR_bi, SVM_bi =eval_model(X_bi)\n",
    "LR_tri, SVM_tri =eval_model(X_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7628262826282628,\n",
       " 0.7677767776777678,\n",
       " 0.7781278127812782,\n",
       " 0.7812781278127813,\n",
       " 0.7712742008104457,\n",
       " 0.7573165240882486,\n",
       " 0.7730751913552454,\n",
       " 0.7807294011706438,\n",
       " 0.7726249437190454,\n",
       " 0.7879333633498424]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_uni "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7637263726372637,\n",
       " 0.77002700270027,\n",
       " 0.7772277227722773,\n",
       " 0.7817281728172817,\n",
       " 0.7726249437190454,\n",
       " 0.7573165240882486,\n",
       " 0.7730751913552454,\n",
       " 0.7816298964430437,\n",
       " 0.7739756866276452,\n",
       " 0.7888338586222422]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_uni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7628262826282628,\n",
       "  0.7677767776777678,\n",
       "  0.7781278127812782,\n",
       "  0.7812781278127813,\n",
       "  0.7712742008104457,\n",
       "  0.7573165240882486,\n",
       "  0.7730751913552454,\n",
       "  0.7807294011706438,\n",
       "  0.7726249437190454,\n",
       "  0.7879333633498424],\n",
       " [0.7637263726372637,\n",
       "  0.77002700270027,\n",
       "  0.7772277227722773,\n",
       "  0.7817281728172817,\n",
       "  0.7726249437190454,\n",
       "  0.7573165240882486,\n",
       "  0.7730751913552454,\n",
       "  0.7816298964430437,\n",
       "  0.7739756866276452,\n",
       "  0.7888338586222422])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_bi, SVM_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7628262826282628,\n",
       "  0.7677767776777678,\n",
       "  0.7781278127812782,\n",
       "  0.7812781278127813,\n",
       "  0.7712742008104457,\n",
       "  0.7573165240882486,\n",
       "  0.7730751913552454,\n",
       "  0.7807294011706438,\n",
       "  0.7726249437190454,\n",
       "  0.7879333633498424],\n",
       " [0.7637263726372637,\n",
       "  0.77002700270027,\n",
       "  0.7772277227722773,\n",
       "  0.7817281728172817,\n",
       "  0.7726249437190454,\n",
       "  0.7573165240882486,\n",
       "  0.7730751913552454,\n",
       "  0.7816298964430437,\n",
       "  0.7739756866276452,\n",
       "  0.7888338586222422])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_tri, SVM_tritop_unigrams = unigram_counts.most_common(100)\n",
    "top_tokenized = uni_tokenizer_counts.most_common(100)\n",
    "data = pd.concat([train_data, dev_data])\n",
    "top_bigrams = bigram_counts.most_common(100)\n",
    "data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(tweets):\n",
    "    for word in [u[0] for u in top_unigrams]:\n",
    "        tweets[word] = tweets['tweet'].str.contains(word).astype(int)\n",
    "    #print(tweets)\n",
    "    word_counts = []\n",
    "    swear_counts = []\n",
    "    at_counts = []\n",
    "    bad_words_set = set(open(\"bad-words.txt\").read().split())\n",
    "\n",
    "    for tweet in tweets['tweet']:\n",
    "        tweet_words = tweet.split()\n",
    "        word_counts.append(len(tweet_words))\n",
    "        tot_bad = 0\n",
    "        #print(tweet_words)\n",
    "        for word in tweet_words:                #Use regexs? \n",
    "            word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        swear_counts.append(tot_bad)\n",
    "        at_count = tweet_words.count('@')\n",
    "        at_counts.append(at_count)\n",
    "\n",
    "    tweets['Word Counts'] = word_counts\n",
    "    tweets['Swear Counts'] = swear_counts\n",
    "    tweets['@ Counts'] = at_counts\n",
    "    X = tweets[[col for col in tweets.columns if col!=\"tweet\"]].values\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tokenized_tweets(tweets):\n",
    "    for word in [u[0] for u in top_tokenized]:\n",
    "        if len(word) > 1:\n",
    "            tweets[word] = tweets['tweet'].str.contains(word).astype(int)\n",
    "    word_counts = []\n",
    "    swear_counts = []\n",
    "    at_counts = []\n",
    "    bad_words_set = set(open(\"bad-words.txt\").read().split())\n",
    "\n",
    "    for tweet in tweets['tweet']:\n",
    "        tweet_words = tweet.split()\n",
    "        word_counts.append(len(tweet))\n",
    "        tot_bad = 0\n",
    "        for word in tweet:                #Use regexs? \n",
    "            #word = word.replace(\".\",\"\").replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\n",
    "            if word.lower() in bad_words_set:\n",
    "                tot_bad+=1\n",
    "        swear_counts.append(tot_bad)\n",
    "        at_count = tweet.count('@')\n",
    "        at_counts.append(at_count)\n",
    "\n",
    "    tweets['Word Counts'] = word_counts\n",
    "    tweets['Swear Counts'] = swear_counts\n",
    "    tweets['@ Counts'] = at_counts\n",
    "    X_tokenized = tweets[[col for col in tweets.columns if col!=\"tweet\"]].values\n",
    "    return X_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = data[['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_tweets(tweets)\n",
    "X_tokenized = process_tokenized_tweets(tweets)\n",
    "y = data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 1, 1, 0],\n",
       "       [1, 0, 0, ..., 1, 1, 0],\n",
       "       [1, 1, 0, ..., 1, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 1, 1, 0],\n",
       "       [1, 0, 1, ..., 1, 1, 0],\n",
       "       [0, 0, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda2/envs/nlu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
    "LR_scores = []\n",
    "SVM_scores = []\n",
    "NB_scores = []\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    LR = LogisticRegression(fit_intercept=True, max_iter=1000, solver='lbfgs', multi_class='ovr')\n",
    "    svm = SVC(gamma='auto') \n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    \n",
    "    LR.fit(X_train, y_train)\n",
    "    y_LR_predict = LR.predict(X_test)\n",
    "    LR_scores.append(precision_recall_fscore_support(y_test, y_LR_predict, average='macro', labels=[0, 1, 2]))\n",
    "                     \n",
    "    svm.fit(X_train, y_train)\n",
    "    y_svm_predict = svm.predict(X_test)\n",
    "    SVM_scores.append(precision_recall_fscore_support(y_test, y_svm_predict, average='macro', labels=[0, 1, 2]))\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    y_NB_predict = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    NB_scores.append(precision_recall_fscore_support(y_test, y_NB_predict, average='macro', labels=[0, 1, 2]))\n",
    "#naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_precision(results):\n",
    "    total = 0\n",
    "    num_rows = 0\n",
    "    for row in results:\n",
    "        total += row[0]\n",
    "        num_rows += 1\n",
    "    return total / num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
    "LR_scores_tok = []\n",
    "SVM_scores_tok = []\n",
    "\n",
    "for train_index, test_index in cv.split(X_tokenized):\n",
    "    LR = LogisticRegression(fit_intercept=True, max_iter=1000, solver='lbfgs', multi_class='ovr')\n",
    "    svm = SVC(gamma='auto') \n",
    "    X_train, X_test, y_train, y_test = X_tokenized[train_index], X_tokenized[test_index], y[train_index], y[test_index]\n",
    "    LR.fit(X_train, y_train)\n",
    "    LR_scores_tok.append(LR.score(X_test, y_test))\n",
    "    svm.fit(X_train, y_train)\n",
    "    SVM_scores_tok.append(svm.score(X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8361836183618362,\n",
       " 0.8352835283528353,\n",
       " 0.851935193519352,\n",
       " 0.873987398739874,\n",
       " 0.8536695182350292,\n",
       " 0.8631247185952273,\n",
       " 0.8572714993246285,\n",
       " 0.8712291760468257,\n",
       " 0.8635749662314273,\n",
       " 0.8703286807744259]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_scores_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8618361836183618,\n",
       " 0.8550855085508551,\n",
       " 0.8672367236723673,\n",
       " 0.8861386138613861,\n",
       " 0.8716794236830256,\n",
       " 0.875281404772625,\n",
       " 0.8779828905898244,\n",
       " 0.8928410625844214,\n",
       " 0.8829356145880234,\n",
       " 0.8793336334984241]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8186318631863186,\n",
       " 0.8181818181818182,\n",
       " 0.833033303330333,\n",
       " 0.8424842484248425,\n",
       " 0.819900945520036,\n",
       " 0.8212516884286357,\n",
       " 0.829806393516434,\n",
       " 0.845114813147231,\n",
       " 0.820351193156236,\n",
       " 0.8460153084196308]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_scores_tok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8604860486048604,\n",
       " 0.8577857785778578,\n",
       " 0.864986498649865,\n",
       " 0.8771377137713772,\n",
       " 0.8680774425934263,\n",
       " 0.8671769473210266,\n",
       " 0.8766321476812247,\n",
       " 0.884736605132823,\n",
       " 0.8757316524088249,\n",
       " 0.8833858622242233]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_scoresLR_precision = get_avg_precision(LR_scores)\n",
    "SVM_precision = get_avg_precision(SVM_scores)\n",
    "NB_precision = get_avg_precision(NB_scores)\n",
    "LR_precision, SVM_precision, NB_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
